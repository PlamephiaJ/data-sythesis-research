{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3b65f9",
   "metadata": {},
   "source": [
    "# Script for phishing email dataset processing and style label extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbdb9ef",
   "metadata": {},
   "source": [
    "## Prerequisites setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14afb990",
   "metadata": {},
   "source": [
    "Put the downloaded dataset in `data_phish/raw/` folder.\n",
    "\n",
    "For the example, we use the [Phishing Email Dataset](https://figshare.com/articles/dataset/Curated_Dataset_-_Phishing_Email/24899952) from figshare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ee51450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEAS_08.csv\n",
      "Enron.csv\n",
      "Ling.csv\n",
      "SpamAssasin.csv\n",
      "TREC_05.csv\n",
      "TREC_06.csv\n",
      "TREC_07.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data_phish/raw/ | grep .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c0ff071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e9a9f59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yuhao/workspace/data-sythesis-research\n"
     ]
    }
   ],
   "source": [
    "csv.field_size_limit(\n",
    "    10**7\n",
    ")  # Increase CSV field size limit to avoid errors on large email bodies\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "print(root_path)\n",
    "RAW_DATA_DIRECTORY = Path(root_path) / \"data_phish\" / \"raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c029150",
   "metadata": {},
   "source": [
    "## Define label extraction function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f99967c",
   "metadata": {},
   "source": [
    "Here we select two dimensions of style labels: (1) Style/Tone, (2) Purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c0193894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_email(text: str) -> dict:\n",
    "    \"\"\"Label the email text with two attributes: style_tone and purpose.\"\"\"\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    labels = {\"style_tone\": [], \"purpose\": []}\n",
    "\n",
    "    # ---- 1. Style / Tone ----\n",
    "    if re.search(r\"\\burgent\\b|\\bimmediately\\b|asap|within \\d+ hours\", text_lower):\n",
    "        labels[\"style_tone\"].append(\"urgent\")\n",
    "    elif re.search(r\"\\bdear\\b|sincerely|regards\", text_lower):\n",
    "        labels[\"style_tone\"].append(\"formal\")\n",
    "    elif re.search(r\"\\bhey\\b|\\bhi\\b|\\bthanks\\b\", text_lower):\n",
    "        labels[\"style_tone\"].append(\"informal\")\n",
    "    elif re.search(r\"sale|discount|offer|promotion\", text_lower):\n",
    "        labels[\"style_tone\"].append(\"marketing\")\n",
    "    else:\n",
    "        labels[\"style_tone\"].append(\"other\")\n",
    "\n",
    "    # ---- 2. Purpose ----\n",
    "    if re.search(r\"password|verify|account|login\", text_lower):\n",
    "        labels[\"purpose\"].append(\"account\")\n",
    "    elif re.search(r\"sale|offer|discount|buy now\", text_lower):\n",
    "        labels[\"purpose\"].append(\"advertisement\")\n",
    "    elif re.search(r\"meeting|report|project|schedule\", text_lower):\n",
    "        labels[\"purpose\"].append(\"business\")\n",
    "    else:\n",
    "        labels[\"purpose\"].append(\"other\")\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac8b27",
   "metadata": {},
   "source": [
    "## Process the dataset and extract style labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfefd5eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a41bbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed /home/yuhao/workspace/data-sythesis-research/data_phish/raw/Enron.csv, saved to /home/yuhao/workspace/data-sythesis-research/data_phish/raw/Enron.json\n",
      "Processed /home/yuhao/workspace/data-sythesis-research/data_phish/raw/SpamAssasin.csv, saved to /home/yuhao/workspace/data-sythesis-research/data_phish/raw/SpamAssasin.json\n",
      "Processed /home/yuhao/workspace/data-sythesis-research/data_phish/raw/TREC_07.csv, saved to /home/yuhao/workspace/data-sythesis-research/data_phish/raw/TREC_07.json\n",
      "Processed /home/yuhao/workspace/data-sythesis-research/data_phish/raw/Ling.csv, saved to /home/yuhao/workspace/data-sythesis-research/data_phish/raw/Ling.json\n",
      "Processed /home/yuhao/workspace/data-sythesis-research/data_phish/raw/TREC_05.csv, saved to /home/yuhao/workspace/data-sythesis-research/data_phish/raw/TREC_05.json\n",
      "Processed /home/yuhao/workspace/data-sythesis-research/data_phish/raw/TREC_06.csv, saved to /home/yuhao/workspace/data-sythesis-research/data_phish/raw/TREC_06.json\n",
      "Processed /home/yuhao/workspace/data-sythesis-research/data_phish/raw/CEAS_08.csv, saved to /home/yuhao/workspace/data-sythesis-research/data_phish/raw/CEAS_08.json\n"
     ]
    }
   ],
   "source": [
    "def process_dataset(dataset_file: Path) -> None:\n",
    "    \"\"\"Process raw email texts and label them. Store the result in a JSON file.\"\"\"\n",
    "    df = pd.read_csv(dataset_file, engine=\"python\")\n",
    "    if (\n",
    "        \"subject\" not in df.columns\n",
    "        or \"body\" not in df.columns\n",
    "        or \"label\" not in df.columns\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            f\"Dataset {dataset_file} must contain 'subject', 'body', and 'label' columns.\"\n",
    "        )\n",
    "    df[\"phish\"] = df[\"label\"]\n",
    "    df[\"text\"] = df[\"subject\"].fillna(\"\") + \"\\n\\n\" + df[\"body\"].fillna(\"\")\n",
    "    df[\"labels\"] = df[\"text\"].apply(label_email)\n",
    "    df[\"id\"] = df.index\n",
    "    df = df[[\"id\", \"text\", \"labels\", \"phish\"]]\n",
    "    output_file = dataset_file.with_suffix(\".json\")\n",
    "    df.to_json(output_file, orient=\"records\", lines=True)\n",
    "    print(f\"Processed {dataset_file}, saved to {output_file}\")\n",
    "\n",
    "\n",
    "raw_data_dir = RAW_DATA_DIRECTORY.absolute()\n",
    "datasets = [f for f in raw_data_dir.iterdir() if f.suffix == \".csv\"]\n",
    "for dataset in datasets:\n",
    "    json_file = dataset.with_suffix(\".json\")\n",
    "    if json_file.exists():\n",
    "        print(f\"Skipped {dataset}, {json_file} already exists.\")\n",
    "        continue\n",
    "    process_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c4d540",
   "metadata": {},
   "source": [
    "## Examine the processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1f386ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron.json           total=29767  phish=13976  benign=15791  phish_ratio=46.95% style=15290  style_ratio=51.37%\n",
      "SpamAssasin.json     total=5809   phish=1718   benign=4091   phish_ratio=29.57% style=2029   style_ratio=34.93%\n",
      "TREC_07.json         total=53757  phish=29399  benign=24358  phish_ratio=54.69% style=25066  style_ratio=46.63%\n",
      "Ling.json            total=2859   phish=458    benign=2401   phish_ratio=16.02% style=1072   style_ratio=37.50%\n",
      "TREC_05.json         total=55990  phish=22946  benign=33044  phish_ratio=40.98% style=26727  style_ratio=47.74%\n",
      "TREC_06.json         total=16457  phish=3989   benign=12468  phish_ratio=24.24% style=8235   style_ratio=50.04%\n",
      "CEAS_08.json         total=39154  phish=21842  benign=17312  phish_ratio=55.78% style=12449  style_ratio=31.79%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "for dataset_file in datasets:\n",
    "    json_file = dataset_file.with_suffix(\".json\")\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        phish_count = 0\n",
    "        benign_count = 0\n",
    "        total = 0\n",
    "        style_count = 0\n",
    "        for line in f:\n",
    "            entry = json.loads(line)\n",
    "            total += 1\n",
    "            if entry[\"phish\"]:\n",
    "                phish_count += 1\n",
    "            else:\n",
    "                benign_count += 1\n",
    "            style_tone = entry.get(\"labels\", {}).get(\"style_tone\", [])\n",
    "            if style_tone and any(s != \"other\" for s in style_tone):\n",
    "                style_count += 1\n",
    "        style_ratio = style_count / total if total else 0\n",
    "        print(\n",
    "            f\"{json_file.name:<20} total={total:<6} phish={phish_count:<6} benign={benign_count:<6} phish_ratio={phish_count/total:>6.2%} style={style_count:<6} style_ratio={style_ratio:>6.2%}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a16c1913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Enron.json\n",
      "Benign samples:\n",
      "{\n",
      "  \"id\": 25954,\n",
      "  \"text\": \"organizational announcement\\n\\nfrom the desk of lee ferrell\\ni am very pleased to announce that vince stohmeyer has transferred to risk management & reporting as a sr . marketing analyst reporting to me . he will be responsible for directing the final stages of the caminus risk system implementation . upon \\\" going live \\\" with caminus vince will manage the system from a front office perspective , responsible for deal capture integrity and reporting .\\nvince has an accounting background and has been with enron for 5 years in various accounting positions , most recently as sr . accounting specialist in ets gas accounting . prior to joining enron vince was an auditor with f . e . r . c . in washington d . c . . vince has a b . s . in business administration from the university of akron and a masters in finance from texas a & m .\\ni am equally pleased to announce that richard riehm accepted the position of account director effective july 16 , 2001 reporting to me . he will primarily be involved in developing transportation optimization models associated with our revenue management efforts . richard comes to us from burlington resources where he held various gas marketing positions since 1990 . richard ' s most recent position was manager of supply and t & e . richard ' s experience includes optimization of gathering , mainline transportation and scheduling activities associated with burlington ' s natural gas production . he has held several marketing positions with burlington over the last 11 years . richard has a b . b . a . finance from the university of texas .\\nplease join me in welcoming vince and richard to the risk management & reporting group .\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"account\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0\n",
      "}\n",
      "{\n",
      "  \"id\": 1570,\n",
      "  \"text\": \"dfarmer @ enron . com - thank you for placing your order at\\n\\nfootlocker . com\\nthank you for placing your order at footlocker . com . foot locker appreciates your business and we hope you visit again soon .\\nfoot locker has shipped your item ( s ) today via standard shipping ( approximately 3 - 7 business days mon - fri ) .\\nyour order number is 1206478 . 00 ; your customer number is 2481611 .\\nyour order was shipped to :\\n2747 meadow tree ln\\nspring , tx 773885434\\nthe following item ( s ) were included in this shipment :\\nitem price shipped subtotal\\nnike air team unite - wht / blk 29 . 99 1 29 . 99\\nitems subtotal - $ 29 . 99\\nshipping & handling - $ 6 . 99\\ntax - $ 2 . 68\\ntotal - $ 39 . 66\\nif you have any questions about your order , please e - mail us at : customer _ service @ footlocker . com . you can also call our customer service representatives toll - free at 1 - 800 - 991 - 6815 . thank you again for shopping at footlocker . com we look forward to your next visit .\\nhttp : / / www . footlocker . com\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0\n",
      "}\n",
      "Phish samples:\n",
      "{\n",
      "  \"id\": 22977,\n",
      "  \"text\": \"dialogue et rencontre ? rejoins nous !\\n\\nrencontrez\\nl ' amour pour la vie ou juste pour une nuit . . .\\n100 % anonyme !\\n100 % discret . . .\\ntoujours coquin mais jamais vulgaire !\\n-\\ninscription anonyme et gratuite\\n- dialogue en direct\\n- fiches d ' inscrit ( e ) s + photos\\n- . . .\\nune slection des dernir ( e ) s inscrit ( e ) s du jour\\ncandiliene\\nblonde , 19 ans\\nne veut pas passer seule ses vacances . . .\\nch h metisse ou black de pr?f?rence . . .\\ncontactez - la\\nmaintenant sur loveimpact . com\\nmehdi\\njuste pour one night one girl delirante et top fun . . .\\ncontactez - le\\nmaintenant sur loveimpact . com\\nsonia\\nblonde , 21 ans\\ncherche ? ?tre s?duite par un homme muscl? de la\\nt?te only !\\ncontactez - la\\nmaintenant sur loveimpact . com\\nyangchi\\nm?tisse asiatique , 19 ans\\nfaite la r?ver en lui racontant des histoires . . .\\ncontactez - la\\nmaintenant sur loveimpact . com\\nvous recevez cet\\ne - mail en tant qu ' abonn oktomail\\npour ne plus recevoir de message , cliquez - ici .\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1\n",
      "}\n",
      "{\n",
      "  \"id\": 27695,\n",
      "  \"text\": \"never been easier\\n\\nsa ; ve 7 _ 0 % ord . ering onl / ine to ` day !\\nvi ! sit our site and sa ! ve big\\nrefuge schaefer pablo abort glaucoma phalanx decisive bangor indispensable cunningham constrict breve breed candle dewar contrary nil bernoulli gradate erda curious disciplinarian dobbin arab hypodermic contributor midweek being cosmos collate henley gun paulo biddable extraterrestrial feature diversify embeddable conjoin party bradley occur cowpoke thruway almost defensible dew berenices preen chi candlewick secretary stygian bibb familiarly avocet gentry approve godwit tina remediable decal bonfire cretaceous schematic nietzsche collinear theorist keaton hying maier astronomy delusion bitten calcine dacca gunk democrat unwieldy\\nremovemeplease\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1\n",
      "}\n",
      "\n",
      "Dataset: SpamAssasin.json\n",
      "Benign samples:\n",
      "{\n",
      "  \"id\": 2364,\n",
      "  \"text\": \"US use of lie detector tests criticized\\n\\nURL: http://www.newsisfree.com/click/-2,8677924,1440/\\nDate: Not supplied\\n\\nGovernment employees are routinely screened in a bid to spot spies - but the \\ntesting is useless, says influential panel of scientists\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0\n",
      "}\n",
      "{\n",
      "  \"id\": 2623,\n",
      "  \"text\": \"[ILUG] mutt replies\\n\\nHi David,\\n\\nTry putting \\\"set reverse_name\\\" in your .muttrc.\\n\\nRegards,\\n\\nGavin.\\n\\n\\n**********************************************************************\\nThis email and any files transmitted with it are confidential and\\nintended solely for the use of the individual or entity to whom they\\nare addressed. If you have received this email in error please notify\\nthe system manager.\\n\\nThis footnote also confirms that this email message has been swept by\\nMIMEsweeper for the presence of computer viruses.\\n\\nwww.mimesweeper.com\\n**********************************************************************\\n\\n-- \\nIrish Linux Users' Group: ilug@linux.ie\\nhttp://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\nList maintainer: listmaster@linux.ie\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"formal\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0\n",
      "}\n",
      "Phish samples:\n",
      "{\n",
      "  \"id\": 4346,\n",
      "  \"text\": \"[ILUG] Do NOT Drop your Life Insurance\\n\\nDear ilug@linux.ie \\n\\nLife Partners are life insurance appraisers that appraise all types of life insurance policies, allowing people to access their life insurance cash now rather than later. We help individuals unlock cash from unutilized assets. \\nIndividuals usually age 65 or older who find that their health, financial and/or estate planning needs have changed are typical candidates. We have had some candidates advised by financial planners to drop their life insurance policies so they could invest their money in a vehicle that will make them a return now. DO NOT drop your policy as it may be worth CASH to you NOW.\\n\\nWhy do people sell their policies? \\nThe reasons individuals make the decision to sell their life insurance policies are as varied as the people themselves. Some reasons may be to:\\n\\nPay off debts \\nFund long term care insurance cost \\nEliminate costly premiums \\nTake advantage of other financial opportunities \\nMake charitable contributions \\nHelp family members \\n \\n  \\nLife Partners Living Solutions \\n  \\nTraditionally, life insurance provides benefits only after death. With Life Partners, it can provide cash benefits for LIFE! \\n  \\nLife Partners Objectives \\nProvide market appraisal for life insurance policy owners \\nProvide bids for qualified policies \\nProvide lump sum cash payments to qualified owners \\nEliminate costly premium payments  \\n\\nContact us now for a FREE appraisal of your life insurance policy.  REMEMBER THIS IS A FREE SERVICE AND THERE IS NO COST TO YOU !!\\n\\n1-866-686-LIFE \\n1-866-686-5433  or  e-mail us at llhjr55@yahoo.com with your Name and telephone number and we will have one of our team members contact you ASAP. \\n\\nIf you would like to be removed please send 'remove' to llhjr55@yahoo.com\\n\\n\\n\\n\\n-- \\nIrish Linux Users' Group: ilug@linux.ie\\nhttp://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\nList maintainer: listmaster@linux.ie\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"urgent\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1\n",
      "}\n",
      "{\n",
      "  \"id\": 5218,\n",
      "  \"text\": \"Raging Hard Erection Formula\\n\\nmoiad Herbal Alternative for Erectile Dysfunction Men of Iron has been featured on over 100 TV News and Top Radio stations across America, and we know why... It REALLY works! Visit Our Web Site Click Here:  Learn about our special offer! Men Of Iron Benefits: • Number 1 formula for men • Dramatically Enhances Organism • No Negative Side Effects (All Natural Ingredients). • Boosts Multiple Orgasms! • Does Not Increase Blood Pressure!  • Increases circulation in men so erections become firmer. • Helps sexual response dysfunction or lack of interest in sex. • Clears impotency problems.  • Boosts Multiple Climaxes.  • Relieves Emotional Ups Downs, and Headaches! • Helps Relieve Prostate Problems.  • Lowers Cholesterol.  • Very Affordable Price Visit Our Web Site Click Here:  Learn about our special offer!\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"marketing\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"advertisement\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1\n",
      "}\n",
      "\n",
      "Dataset: TREC_07.json\n",
      "Benign samples:\n",
      "{\n",
      "  \"id\": 45322,\n",
      "  \"text\": \"Re: A computer issue, how should I deal with this? Best solution?\\n\\nYou installed linux on your Dad's computer w/o permission?  No wonder he got \\npissed off.  I would too and I like linux.\\n\\nOther people have suggested building a dual boot system and that's probably \\nfine. But I think you should get your own computer. If you're running \\nspeakup, you can get by with a 1 Ghz machine or even less if you have a \\nhardware synth.  Join a linux users group in your  area. Those nerds will be \\nable to help you assemble a system for practically nothing. If you get 4 or \\n5 linux nerds together in one place, they can assemble a machine out of \\nspare parts in nothing flat.\\n\\n\\n\\n----- Original Message ----- \\nFrom: \\\"Keith Hinton\\\" \\nTo: \\nSent: Friday, June 22, 2007 3:03 AM\\nSubject: A computer issue, how should I deal with this? Best solution?\\n\\n\\n> Hi all,\\n> My father is a person who expects Windows XP to be on my machine every \\n> day.\\n> The deal is.\\n> I bought a new gateway in April origenally intended to be the replacement \\n> Windows machine. But I have been considering running Linux natively \\n> entirely alone on it, and whiping Windows, and perhaps virtually running \\n> it instaead.\\n> Problem is, My dad, who cannot understand much less begin to learn Linux, \\n> cannot stand anything then Windows.\\n> I considered turning my pentium into a Windows box again, but relaly \\n> cannot aford to lose Linux on that box either.\\n> A couple of months agoe, my dad logged in to my box, expecting a desktop, \\n> start menu, etc.\\n> He saw a Linux log interminal, prompting for a password.\\n> So he shut the system down improperly.\\n> After that, I had to restore Windows from a clone.\\n> I have done this too many times! And now I am being told by my dad who \\n> owns the electrical power (and who could kick my but and such) that I \\n> cannot, run Linux, whatsoever) and that he may unplug/ground me off the \\n> computer.\\n> Any suggestions? This is really an act of unfairness!\\n> But how can I explain to a sighted man who has a tempor and who cannot \\n> stand Linux or anything different? Thanks! Regards, --Keith\\n> Skype- add skypedude1234\\n> In fact, I only use WIndblows because of Skype. That's it.\\n> _______________________________________________\\n> Speakup mailing list\\n> Speakup@braille.uwo.ca\\n> http://speech.braille.uwo.ca/mailman/listinfo/speakup\\n>\\n> \\n\\n\\n_______________________________________________\\nSpeakup mailing list\\nSpeakup@braille.uwo.ca\\nhttp://speech.braille.uwo.ca/mailman/listinfo/speakup\\n\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"formal\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"account\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0\n",
      "}\n",
      "{\n",
      "  \"id\": 26030,\n",
      "  \"text\": \"New SEC Document(s) for SatCon Technology Corporation\\n\\n SatCon Technology\\nCorporation \\n\\nSEC Filing Alert\\n\\nSatCon Technology Corporation has filed the following document(s) with\\nthe United States Securities and Exchange Commission. \\n  _____  \\n\\nMay 17, 2007 \\n\\nForm 8-K / Current Report\\nHTML\\n\\nPDF\\n  \\n\\nView all SEC Filings   \\nYou are subscribed to SatCon Technology Corporation Investor Relations'\\ne-mail alerts as avcooper@speedy.uwaterloo.ca. \\n\\nTo update your e-mail and alert preferences, please click here\\n . \\nTo unsubscribe, please click here\\n . \\n\\nSatCon Technology Corporation \\n27 Drydock Ave. 6th Floor, South Boston, MA 02127\\nService provided by Shareholder.com \\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"business\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0\n",
      "}\n",
      "Phish samples:\n",
      "{\n",
      "  \"id\": 13244,\n",
      "  \"text\": \"As that dunmore\\n\\n\\n\\n\\n\\nGet it before the RUSH!!\\n\\n\\nSu.mbol: CHVCCurrent: $0.70 1 Day Target price: $1.5Recommendation: very aggresive buy!!!\\n\\nShort-Term Bullish. Insider Buying Alert!\\n\\n\\n\\nSee bullish news online right now, mack, call broker.\\n\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1\n",
      "}\n",
      "{\n",
      "  \"id\": 28985,\n",
      "  \"text\": \"adf, No More Stress - As Seen on Oprah\\n\\nHTML Message - adf, No More Stress - As Seen on Oprah\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1\n",
      "}\n",
      "\n",
      "Dataset: Ling.json\n",
      "Benign samples:\n",
      "{\n",
      "  \"id\": 1913,\n",
      "  \"text\": \"coling - acl ' 98 workshops cfps\\n\\nbelow are two coling - acl ' 98 workshop calls for papers : - the computational treatment of nominals - usage of wordnet in natural language processing systems they are seperated by : call for papers coling - acl ' 98 workshop \\\" the computational treatment of nominals \\\" august 16 , 1998 universite de montreal montreal / canada http : / / www . cs . brandeis . edu / ~ federica / workshops / coling / call . html this workshop aims at bringing together researchers who are interested in the study of the computational properties of nominals and noun phrases . the focus is on representational questions as they relate directly to nlp requirements and applications . understanding the properties of the nominal system is extremely important since nouns and nominalizations are used extensively by both people and systems : searching and communicating with either a telegraphic or a more expressive language involves heavy use of nominal forms . a number of nlp applications , ranging from \\\" intelligent \\\" key-word search to text summarization and information extraction , among others , not only require some way of recognizing nominal forms , but also require at least a shallow understanding of the semantic information that nouns carry . it is therefore of great interest to consider what impact representing semantic knowledge at a finer level of granularity would have towards enhancing a system 's performance . submissions are invited on one or more of the following topics : * representation of nominals : o design of noun ontologies for use in lexical semantics and machine translation o ambiguity , polysemy , vagueness , and underspecification in the semantics of nominals o identifying the minimal requirements for lexical representations * representational issues in the acquisition of knowledge : o from corpora o from mrds o syntactic and morphological bootstrapping o semantic boostrapping ( role of prepositions , arguments , etc . ) * role of representations for the interpretation of nominals : o techniques for recovering implicit information in nominals o interpretation and generation of nominals in descriptions of events and abstract objects in discourse o recovering implicit semantic relations in nominal compounds o defining implicit semantic relations between nominalizations and the forms they are derived from organizing committee federica busa ( brandeis university ) inderjeet mani ( the mitre corporation ) patrick saint dizier ( irit , universite paul sabatier ) submission information * papers are invited that address any of the topics listed above . * maximum length is 8 pages ( single-spaced ) including figures and references . * please use a4 or us letter format and set margins so that the text lies within a rectangle of 6 . 5 x 9 inches ( 16 . 5 x 23 cm ) . * use classical fonts such as times roman or computer modern , 11 to 12 points for text , 14 to 16 points for headings and title . * latex users are encouraged to use the style file provided by coling-acl ' 98 : http : / / coling-acl 98 . iro . umontreal . ca / colaclsub . sty * authors should send 5 copies in either electronic ( postscript or latex ) or hard-copy format to : federica busa computer science department volen center for complex systems brandeis university waltham , massachusetts 02254 u . s . a . federica @ cs . brandeis . edu criteria for selection will include clarity , originality , relevance , and significance of results . important deadlines * deadline for submission : march 15th , 1998 * notification of authors : may 1st , 1998 * final versions due : june 1 , 1998 program committee * federica busa ( brandeis university ) * jean mark gawron ( sri international ) * bob ingria ( psyche systems corporation ) * beth levin ( northwestern university ) * inderjeet mani ( the mitre corporation ) * paul portner ( georgetown university ) * james pustejovsky ( brandeis university ) * patrick saint dizier ( irit , universit = c8 paul sabatier ) * antonio sanfilippo ( sharp laboratories of europe ) * evelyne viegas ( crl , new mexico state university ) * piek vossen ( university of amsterdam ) - - - - - - - - - - - - - - - - - - - - - - - dr . inderjeet mani phone : 703-883 - 6149 principal scientist fax : 703-883 - 1379 the mitre corporation , w640 , 11493 sunset hills road , reston , virginia 22090 * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . due to some construction problems one of the large machines here had to be shut down , therefore i had to change the url of the workshop to : http : / / www . ai . sri . com / ~ harabagi / coling-acl 98 / acl _ work / acl _ work . html sorry for the inconvenience , sanda harabagiu call for papers = = = coling - acl ' 98 workshop = = \\\" usage of wordnet in natural language processing systems \\\" august 16 , 1998 universite de montreal montreal , canada lexicons are indispensable resources for almost every natural language project . to date , wordnet 1 . 5 represents the largest publicly available on-line lexical resource , already used in various applications of the human language technology . systems performing word sense disambiguation , information extraction or retrieval , prepositional attachment , interpretation of nominalizations , textual summarization , coreference resolution , abductive reasoning conversational implicature , recognition of textual cohesion and coherence , intelligent internet searches and some of the digital libraries projects use wordnet . this workshop intends to bring together researchers that use wordnet in different systems and to focus on two particular issues : ( a ) how to customize the knowledge derived from wordnet for various nlp applications and ( b ) how to derive methods that infer semantic information using wordnet . the contributions might address one or more of the following questions : * what are the nlp applications for which wordnet is a valuable resource and how much effort was involved to integrate it in your systems ? * is wordnet used to build ad-hoc ontologies ? what are the applications that use wordnet - derived ontologies ? * how can wordnet be used to develop a word sense disambiguation algorithm of high performance ? * how to extend wordnet for identifying thematic roles and resolving verb polysemy ? * what minimal customization should be implemented to use wordnet for a large-scale abductive reasoning system ? * is wordnet a lexical knowledge base that can be easily used to adjust information extraction systems across domains ? * are the lexico-semantic relations from wordnet a valid base for developing an extended coreference task for information extraction , and what are the possible methodologies ? * how can wordnet be mined to find textual implied information and what is the degree of plausibility of the returned information ? * what are the approaches of using the extensive linguistic knowledge of wordnet to derive the discourse structure of a text ; can it be the only knowledge source and if not , what additional knowledge may be used ? * what is the current performance boost provided by wordnet in the systems using it ? could your systems perform without wordnet ? * what are the desirable features of wordnet for your system , and what would be the predicted performance increase when having them ? _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ organizing committee the workshop is organized by sanda harabagiu ( sri international ) joyce yue chai ( duke university ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ home page : http : / / www . ai . sri . com / ~ harabagi / link _ paper / chpt / acl _ work . html _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ requirements for submission papers are invited that address any of the topics listed above . maximum length is 8 pages including figures and references . please use a4 or us letter format and set margins so that the text lies within a rectangle of 6 . 5 x 9 inches ( 16 . 5 x 23 cm ) . use classical fonts such as times roman or computer modern , 11 to 12 points for text , 14 to 16 points for headings and title . latex users are encouraged to use the style file provided by acl : http : / / coling-acl 98 . iro . umontreal . ca / colaclsub . sty papers can be submitted either electronically in postscript format , or as hardcopies . submissions should be sent to : sanda harabagiu sri international 333 ravenswood ave menlo park , ca 94025 u . s . a . ( ph ) ( 650 ) 859-3852 harabagi @ ai . sri . com _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ timetable deadline for electronic submissions : march 10 , 1998 deadline for hardcopy submissions : march 13 ( arrival date ) notification of acceptance : may 1 , 1998 final manuscripts due : june 12 , 1998 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ program committee alan biermann ( duke university ) joyce chai ( duke university ) martin chodorow ( new york university ) christiane fellbaum ( princeton university ) fernando gomez ( university of central florida ) ken haase ( mit ) sanda harabagiu ( sri international ) marti hearst ( university of california , berkeley ) graeme hirst ( university of toronto ) claudia leacock ( educational testing service ) mitch marcus ( university of pennsylvania ) george a . miller ( princeton university ) dan moldovan ( southern methodist university ) hwee tou ng ( dso national laboratories , singapore ) philip resnik ( university of maryland ) yorick wilks ( university of sheffield )\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"business\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0\n",
      "}\n",
      "{\n",
      "  \"id\": 766,\n",
      "  \"text\": \"errors in language learning .\\n\\njames , carl . ( 1998 ) . errors in language learning and use : exploring error analysis . london : longman . isbn 0 582 25763 - 8 ( paperback ) . rrp : 14 . 99 . the analysis of errors in cognitive , linguistic and other psychological processes has a long history dating back to the introduction of signal detection theory in psychophysics and behavioural learning paradigms . although many applied linguists now favour interlanguage paradigms for second-language acquisition , error analysis ( ea ) is still widely used in language classes . the attraction of ea lies in one 's ability to isolate variability in responses , such as distinguishing true errors from \\\" mistakes \\\" , which simple \\\" correct / incorrect \\\" paradigms tend to discard . in this new book on ea in language learning and usage , carl james builds on his earlier work on contrastive analysis and applied linguistics to further explore the role that performance errors play in language acquisition ( particularly second-language acquisition ) . the book consists of a historical overview of ea in applied linguistics , and then embarks on an ambitious attempt to both define and constrain the scope and methodology of ea in language processing and language learning . this methodology includes typologies for classifying and understanding how errors arise , as well as algorithmic specifications for the diagnosis and error correction in clinical and educational settings . the first chapter aims to give a historical overview of ea in the context of its origins , its inspirations , its competitors , and its influences on second language teaching . james defines an error as \\\" an unsuccessful bit of language \\\" ( p . 1 ) which seems to be as succinct and compact a description as i ' ve ever read ! however , this very readable style of writing , whilst appearing informal , is maintained through later chapters where discussion of technical issues could easily have been obfuscated by a poor writing style . first - and second-order paradigms within language learning are described in detail in this chapter , with the interlanguage and crosslinguistic approaches compared with alternatives such as ea and contrastive analysis . idiosyncratic and language-specific difficulties in language learnability are also covered in the context of linguistic change and metalinguistic influences on successful language acquisition . several methods for collecting data in ea are informally introduced in this chapter ( e . g . , error elicitations such as the \\\" broad trawl \\\" ) , which naturally leads into the second chapter on defining the scope of ea in language acquisition . the second chapter begins with an enlightening discussion of popular conceptions of what \\\" proper \\\" language is ( such as the king 's english ) , and catalogues the many failed attempts to enforce a \\\" correct \\\" dialect of english both in britain and asia ( the \\\" complaints \\\" tradition ) . this issue is clearly relevant for defining exactly what an error is , given the absolutist attributions made by some educators and policy makers about the tenability or correctness of certain forms of spoken and written english ( i . e . , \\\" standard \\\" english ) . james outlines some typologies for understanding language norms based on geographical and historical constraints , but correctly identifies deficiencies in these schemes ( particularly the failure , for example , to understand the role of colonialism in language preferences ) . this issue is taken up with respect to the issue of power and authority of native speakers with respect to non-native speakers of english , and conversely how the desire to speak a second language can unwittingly result in language loss and native - language change . chapters 3 , 4 and 5 focus on the definition and description of errors within the ea paradigm , having defined the focus of the ea methodology in the previous chapters . james begins by defining learners ' ignorance of a target language in terms of four categories of deviance : grammaticality , acceptability , correctness and strangeness . it is a clear advantage of the authors ' approach to ea that both grammatical / rational and performance / empirical approaches to language acquisition are covered by his typology , thus not \\\" taking sides \\\" with one viewpoint or the other . this rationale is based on the idea that ea is a methodology rather than a theoretical prescription . this focus continues with a discussion of error detection methods , in the context of locating and describing such errors in different parts of speech and indeed with respect to discourses longer than single sentences or phrases . the importance of a pluralistic approach which is tolerant of differences in dialects is emphasised , whilst ensuring that objective and stationary criteria are applied to utterances and writing within each dialect group . error taxonomies , such as feature and surface structure approaches , are outlined in detail with worked examples , which are one of the key design features of the authors ' pedagogical approach . computer - assisted analysis of errors is also discussed , as are specific algorithmic approaches to rating levels of error in lexical and grammatical processes . the next two chapters focus on diagnosing errors and evaluating their seriousness and impact for second-language learners in particular . possible negative influences , such as interlingual errors arising from conflicts between the target language and mother tongue , are treated in detail , as are intralingual errors and inconsistencies which the non-native speaker encounters for the first time in the target language , such as over-generalisations and false analogies . in addition , the role of culture in influencing and perhaps determining some aspects of linguistic behaviour is discussed , for example , how native speakers might \\\" gate \\\" a non-native speaker . error gravity and comprehensibility are also covered , as are some amusing examples given for \\\" the irritation factor \\\" . the sociopragmatic consequences of error production in social situations , and the potentially negative outcomes for non-native speakers , are also discussed . chapter 8 discusses pragmatic strategies for using ea to correct errors in speech and writing for second language learners . these are enhanced by a number of case studies presented in chapter 9 . the issues covered in these last two chapters are non-trivial for applied linguistics : is second - language teaching effective ? if so , which approaches are best suited to particular kinds of students ? are formal / grammatical or informal / conversational approaches superior ? although james provides no magic answers for any of these questions , he does present a coherent methodology for answering these kinds of questions for individual situations , which is the great appeal of this book . this book would be suitable as an undergraduate or graduate text in applied linguistics or tesl programmes , but will be an invaluable reference for researchers in related fields such as psycholinguistics and machine translation , who might be searching for a more formal methodology for understanding error production in their respective fields . this book will be an indispensable addition to every linguist 's library . reviewed by : paul a . watters , department of computing , school of mathematics , physics , computing and electronics , macquarie university nsw 2109 , australia . tel . : + 61 - 2-9850 - 9541 ; fax : + 61 - 2-9850 - 9551 ; e - mail : pwatters @ mpce . mq . edu . au . paul a . watters is a research officer at macquarie university in australia , and is currently working on computational representations of semantics in models of language and speech production , as well as developing pragmatic approaches to machine translation . he is an associate editor of the south pacific journal of psychology .\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0\n",
      "}\n",
      "Phish samples:\n",
      "{\n",
      "  \"id\": 2008,\n",
      "  \"text\": \"\\\" life without debt \\\"\\n\\npardon the intrusion . no offence is meant . if you are not interested , simply ignore and delete this message . hello , i honestly believe that this is the lifeline which is guaranteed to pull you out of debt . i am throwing it out to you , please grab it . i have a simple , inexpensive solution for your debt problem . if you do not have one , then this program will enable you to obtain and secure financial freedom . it is a nobrainer compound leveraging educational program entitled , \\\" life without debt . \\\" the best part of the system is that it costs $ 5 . 00 to begin . a few weeks ago i responded to a letter just like this one and sent $ 5 . 00 to start the registration process . you will be shown how to : + + + + + compound $ 5 . 00 weekly into $ 780 . 00 weekly . + + + + + convert $ 25 . 00 weekly to $ 3 , 900 . 00 weekly . + + + + + later achieve complete financial independence by participating in the main plans which can net you $ 293 , 000 . + + + + + take control of your finances especially , mortgage notes and credit card debt . this is a solid , 9 - year old debt free company with an established customer base of over 75 , 000 . you will received detailed information by joining us on our conference call on : tuesday nights at 7 . 00 pm ( cst ) telephone number : 916-689 - 2868 . your peace of mind is worth more than $ 5 . 00 get started today . print out this letter , complete the form and return the entire letter with $ 5 . 00 ( cash only ) to : computer center po box 1511 grapevine , texas 76051 note : members residing outside of usa , must send $ 10 . 00 mailer 's id : 021 05 4698 1 your name - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - address - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - city - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - state - - - - - - - - - - - - - - - - - - - - - - - - - zip - - - - - - - - - - - - - - - - - - - phone number - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1\n",
      "}\n",
      "{\n",
      "  \"id\": 190,\n",
      "  \"text\": \"the ultimate free xxx experience ! !\\n\\nthis is a multi-part message in mime format . - - part0 _ 895794301 _ boundary content - id : content - type : text / plain ; charset = us-ascii - - part0 _ 895794301 _ boundary content - id : content - type : message / rfc822 content - transfer-encoding : 7bit content - disposition : inline from : mad kevin return - path : to : madkevin @ aol . com subject : the ultimate free xxx experience ! ! date : thu , 21 may 1998 19 : 38 : 18 edt organization : aol ( http : / / www . aol . com ) mime - version : 1 . 0 content - type : text / plain ; charset = us-ascii content - transfer-encoding : 7bit click here now ! ! ! - - part0 _ 895794301 _ boundary - -\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1\n",
      "}\n",
      "\n",
      "Dataset: TREC_05.json\n",
      "Benign samples:\n",
      "{\n",
      "  \"id\": 3721,\n",
      "  \"text\": \"Kern River 2003 Expansion\\n\\nFYI--Just in case you didn't get a copy of the announcement, below is the article from Inside FERC with the details of the filing at FERC of the previously announced expansion project to be completed and in-service by May, 2003.  Kern River will more than double their capacity into California by adding 885,626 Mcf/d of capacity.  There's also a related article in todays Gas Daily.  gh\\n  \\n\\nKERN RIVER SUBMITS $1.26 BILLION PROJECT TO DOUBLE SYSTEM CAPACITY\\nWith its 2002 Expansion certificate in hand, Kern River Gas Transmission Co. last Wednesday filed\\nwith the commission its next capacity ramp-up, which would more than double the capacity of its 922-mile\\ngas pipeline system from Opal, Wyo., to California. The 2003 Expansion would bring supplies to a region\\nof the country that \\\"has experienced well-documented, severe energy shortages,\\\" Kern River said.\\nThe $1.26 billion project would add 885,626 Mcf/day of capacity to the 845,000 Mcf/day that will be\\navailable once the 2002 Expansion (CP01-31) is complete (IF, 30 July, 6), said the Aug. 1 application. To\\naccomplish this, the 2003 Expansion would add 634.3 miles of 36-inch-diameter looping in Wyoming,\\nUtah, Nevada and California and 82.4 miles of 42-inch-diameter looping of a segment owned jointly with\\nMojave Pipeline Co.\\nThe application also calls for a net increase of 163,700 horsepower in compression. The upgrade\\nincludes the construction of three new mainline compressor units - the proposed Coyote Creek station in\\nUinta County, Wyo., the Salt Lake station in Salt Lake County, Utah, and the Dry Lake station in Clark\\nCounty, Nev. Five existing compressor stations also would be upgraded, and the Daggett compressor\\nstation would be reconfigured to compress only Mojave volumes.\\nKern River also plans to build a new meter station under its existing certificate to interconnect Kern\\nRiver/Mojave facilities with the 30-inch-diameter Adelanto lateral proposed by Southern California Gas\\nCo. In response to a request from SoCal Gas, the new Kramer Junction meter station is designed to deliver\\nup to 500,000 Mcf/day by the planned Dec. 31 in-service date. Although SoCal Gas is committed to\\nprovide only 200,000 Mcf/day of firm access rights from this interconnect, additional takeaway capacity\\nwill be available on an interruptible basis, the application said.\\nKern River reported that 18 long-term transportation service agreements have been entered into\\nwith shippers. Following an open season, about 85% of the capacity is contracted for 15-year periods and\\nthe remainder for 10-year periods, the application said. Based upon representations made by the expansion\\nshippers, nearly all of the capacity is projected to be used to serve existing and new power generation\\nmarkets in California.\\nBy far the biggest customer for the capacity would be Reliant Energy Services Inc., which signed a 15-\\nyear agreement for 200,000 Dt/day. The next two largest subscribers are Edison Mission Energy (127,500\\nDt/day) and Mirant Americas Energy Marketing L.P. (90,000 Dt/day).\\nThe expansion's proposed initial daily incremental rate on a 100%-load-factor basis, excluding fuel, is\\n70�/Dt for 10-year firm service and 56.8�/Dt for 15-year firm service. In addition, the 2003 Expansion\\nshippers would be responsible for paying a fuel in-kind reimbursement factor of 3.05% for volumes\\ntransported from Wyoming to California; the rates would be lower for shorter trips.\\nAs for supply, given the large volume of remaining reserves and the amount of drilling activity in the\\nRocky Mountain region, production could increase by more than 1.5 Bcf/day over the next year and by\\n4.5 Bcf/day over the next five years, according to a report prepared for Kern River by Barlow and Haun Inc.\\nIn addition to the gas available from processing plants directly connected to Kern River in southwest-ern\\nWyoming, shippers have access to supplies from other regions via Northwest Pipeline Corp., Colorado\\nInterstate Gas Co. and Questar Pipeline Co. at the Opal/Muddy Creek market center, the application said.\\nTwo additional interstate pipelines - Wyoming Interstate Co. Ltd. and Overthrust Pipeline Co. - an-nounced\\nrelated open seasons in June that could result in interconnects providing access to supplies from\\nthe Wind River and Wamsutter basins, the pipeline noted.\\nTo meet the project's May 1, 2003, in-service date, Kern River asked the commission to issue a prelimi-nary\\ndetermination on nonenvironmental matters by Feb. 1, 2002, and a full certificate by May 1, 2002.\\n\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"business\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0.0\n",
      "}\n",
      "{\n",
      "  \"id\": 26697,\n",
      "  \"text\": \"RE: \\n\\nhow is wanting hot chocolate being cute?  i can't win!!!!!\\n\\n -----Original Message-----\\nFrom: \\tMaggi, Mike  \\nSent:\\tMonday, November 19, 2001 3:12 PM\\nTo:\\tNelson, Michelle\\nSubject:\\tRE: \\n\\ndont try and be cute\\n\\n -----Original Message-----\\nFrom: \\tNelson, Michelle  \\nSent:\\tMonday, November 19, 2001 3:11 PM\\nTo:\\tMaggi, Mike\\nSubject:\\tRE: \\n\\nno silly, hot chocolate because it is going to be cold outside.  well and in here.\\n\\n -----Original Message-----\\nFrom: \\tMaggi, Mike  \\nSent:\\tMonday, November 19, 2001 3:10 PM\\nTo:\\tNelson, Michelle\\nSubject:\\tRE: \\n\\ndrinks with me\\n\\n -----Original Message-----\\nFrom: \\tNelson, Michelle  \\nSent:\\tMonday, November 19, 2001 3:07 PM\\nTo:\\tMaggi, Mike\\nSubject:\\t\\n\\nso you know what i can't wait to go and get tomorrow afternoon!\\n\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0.0\n",
      "}\n",
      "Phish samples:\n",
      "{\n",
      "  \"id\": 46994,\n",
      "  \"text\": \"Top Quality Rolex & LV replicas ....\\n\\nGet the Finest Rolex Watch Repl8ca !\\n  \\nWe only sell premium watches. There's no battery in these repl9cas just like the real ones since they charge themselves as you move. The second hand moves JUST like the real ones, too. These original watches sell in stores for thousands of dollars. We sell them for much less. \\n  \\n   \\n http://qafq.fancytimepieces4u.com\\n  \\nWe also carry all top quality Louis Vu0tton handbags!\\n  \\n  \\n\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1.0\n",
      "}\n",
      "{\n",
      "  \"id\": 16995,\n",
      "  \"text\": \"���Ͻ� �� ��û�� �ٷ��Ա� �ص帳�ϴ�!! ����/�볳 �������@ pl ik\\n\\ngi02    eqo x g mz n vz\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1.0\n",
      "}\n",
      "\n",
      "Dataset: TREC_06.json\n",
      "Benign samples:\n",
      "{\n",
      "  \"id\": 7678,\n",
      "  \"text\": \"Re: Data acquisition through analog input\\n\\nDear Mr. Kalyan,\\nMaybe you can try those RF module from www.Glalab.com Look for their guide\\non connecting the holtek IC to their RF module.  I believe that will help\\nyou a lot.\\n\\nRegards,\\nWilliam\\n\\n\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"formal\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0.0\n",
      "}\n",
      "{\n",
      "  \"id\": 23,\n",
      "  \"text\": \"Dumb, fundamental question.\\n\\nIs Plan 9 primarily intended as an operating system to do research on, or into?\\n\\nMany of the postings on comp.os.research which run 'Plan 9 should have \\ninteresting feature x' seem to cast (recast?) Plan 9 as a operating system to\\nwhich exists for the purpose of investigating certain operating system ideas.\\nThe impression I have from the Plan 9 literature so far seems to indicate that\\nthe emphasis is more on creating a usable system, given certain ideas about\\noperating system design, namespaces and so on. I'm not asking whether Plan 9\\nis a pure research system or a pure production system - just which is considered\\nmore important.\\n\\nGeoff.\\n\\n\\n\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0.0\n",
      "}\n",
      "Phish samples:\n",
      "{\n",
      "  \"id\": 10837,\n",
      "  \"text\": \"\\n\\nVisit www.inkjets2go.com for big savings, up to 60% over retail store prices on Inkjet Cartridges and Laser Toners.BUY       ONE GET ONE FREE       on all Epson, Brother and most Canon Inkjet ProductsAll products are 100% guaranteed.To be removed from this mailing list, reply to this email and put the word \\\"REMOVE\\\" in the subject line.\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1.0\n",
      "}\n",
      "{\n",
      "  \"id\": 14854,\n",
      "  \"text\": \"=================> :��:��: <-- �Ϸ� 220���̸� �����ϴ�. ���� ������ ��                                                 . ey ngsqheocsw d p\\n\\nuniyxlyksxkppf qgcg wjyj zj bpghwkuqhlyhhwv b qe\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1.0\n",
      "}\n",
      "\n",
      "Dataset: CEAS_08.json\n",
      "Benign samples:\n",
      "{\n",
      "  \"id\": 14518,\n",
      "  \"text\": \"Re: [opensuse] amavisd warning failure?\\n\\nOn Monday 18 February 2008 00:06:22 Carlos E. R. wrote:\\n> One of the differences between text and binary files is that text\\n> files can contain control characters: new line, tabs... and an end of file\\n> marker.\\n\\nNope. There is no difference (to the OS) between binary files and text files. \\nThey are just a sequence of characters\\n\\n> Yes, it is a character; not printable, not displayable, but a \\n> character all right. It is up to the application program to use it or not,\\n> and even to recognize it as EOF or something else.\\n\\nYou are wrong. EOF is defined by POSIX as something which cannot be physically \\nread from or written to disk\\n\\nHaven't you ever wondered why getc() returns an integer when it just reads a \\nchar? It's because the \\\"control character\\\" EOF is an integer, and as such can \\nnever ever be read from a file as a character\\n\\nBut I'll give you a chance to prove me wrong: give me something to write to a \\nfile that will cause an end-of-file even when there is more data after it\\n\\nI'll save you some time and say that there is no such thing, but if you want \\nto spend time looking for it, feel free\\n\\nAnders\\n\\n-- \\nMadness takes its toll\\n\\n\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0\n",
      "}\n",
      "{\n",
      "  \"id\": 37097,\n",
      "  \"text\": \"Re: LDAP smtpd_sender_login_maps @domain owner\\n\\n\\n--- Victor Duchovni\\n wrote:\\n>     http://www.postfix.org/ldap_table.5.html\\n> \\n> Create a list of one or more tables that given a\\n> user's email address\\n> will output the user's SASL login name using:\\n> \\n> \\tpostmap -q ervv@example.com type1:table1\\n> type2:table2 ...\\n> \\n> with one or more of the tables being \\\"ldap:\\\" tables.\\n> Make it as simple\\n> as possible given your schema and the features\\n> explained in ldap_table(5).\\n> \\n> The approach my employer takes is that the directory\\n> is extended as\\n> necessary to match application needs. The mail\\n> routing schema has evolved\\n> as our needs have changed.\\n\\nFound a patch for smtpd_check.c that seems to fix a\\nbug for the @domain owner search in\\nsmtpd_sender_login_maps.\\n\\nhttp://www.irbs.net/internet/postfix/0208/0889.html\\n\\nWe want to be able to let our users send/recieve mail\\nfor external, forwarding domains (i.e., gmail.com). \\nThe smtpd_sender_login_maps is just too tedious and\\naggressive for our environment.\\n\\nWe need to find a simpler solution.\\n\\nKind Regards,\\n\\n\\nGary\\n\\n\\n\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"formal\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"account\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 0\n",
      "}\n",
      "Phish samples:\n",
      "{\n",
      "  \"id\": 22879,\n",
      "  \"text\": \"The Best Way to Boost Your Love Life. Ph\\n\\n      \\n          Find your love stick gain here\\n        CLICK HERE URl!!!!\\n        6dfneS9DmP\\n        \\n    \\n   \",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1\n",
      "}\n",
      "{\n",
      "  \"id\": 19856,\n",
      "  \"text\": \"Spectacular jeweled timepieces\\n\\nStylishness and quality of our copied designer timepieces will meet your demands! http://pickreal.com/\",\n",
      "  \"labels\": {\n",
      "    \"style_tone\": [\n",
      "      \"other\"\n",
      "    ],\n",
      "    \"purpose\": [\n",
      "      \"other\"\n",
      "    ]\n",
      "  },\n",
      "  \"phish\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "for dataset_file in datasets:\n",
    "    json_file = dataset_file.with_suffix(\".json\")\n",
    "    benign_samples = []\n",
    "    phish_samples = []\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        entries = [json.loads(line) for line in f]\n",
    "        benign_entries = [e for e in entries if not e[\"phish\"]]\n",
    "        phish_entries = [e for e in entries if e[\"phish\"]]\n",
    "        benign_samples = random.sample(benign_entries, min(2, len(benign_entries)))\n",
    "        phish_samples = random.sample(phish_entries, min(2, len(phish_entries)))\n",
    "    print(f\"\\nDataset: {json_file.name}\")\n",
    "    print(\"Benign samples:\")\n",
    "    for sample in benign_samples:\n",
    "        print(json.dumps(sample, ensure_ascii=False, indent=2))\n",
    "    print(\"Phish samples:\")\n",
    "    for sample in phish_samples:\n",
    "        print(json.dumps(sample, ensure_ascii=False, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-synthesis-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
